{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归算法\n",
    "\n",
    "## 什么是回归算法？\n",
    "\n",
    "回归算法的目标是找到一个模型，该模型能够预测或估计一个连续的目标变量（通常记为 $ y $ ）基于一个或多个预测变量（通常记为 $ x $）。这就像用一个方程来描述“因变量 $ y $”和“自变量 $ x $”之间的关系。例如，预测房价（$ y $）可能依赖于房屋的大小、位置等因素（$ x $）。\n",
    "\n",
    "回归算法有**线性回归**与**岭回归**两种。\n",
    "\n",
    "### 线性回归\n",
    "\n",
    "线性回归是最基础的回归算法。它假设目标值和特征之间存在线性关系。\n",
    "\n",
    "#### 线性回归工作原理\n",
    "\n",
    "- **模型形式**：线性回归试图找到一组权重（$ w $），使得 $ y = wx + b $ 尽可能接近实际值。\n",
    "- **目标**：通过最小化预测值和实际值之间的差异（通常使用均方误差）来确定权重。\n",
    "\n",
    "#### 线性回归适用场景\n",
    "\n",
    "- 当数据集特征与目标变量之间的关系可以合理地假设为线性时。\n",
    "- 在解释模型和结果很重要的场合，因为线性回归模型易于解释。\n",
    "\n",
    "### 岭回归\n",
    "\n",
    "岭回归是线性回归的一种变体，用于处理共线性（即输入特征之间高度相关）数据，其通过引入正则化项来防止过拟合。\n",
    "\n",
    "#### 岭回归工作原理\n",
    "\n",
    "- **正则化**：岭回归在优化目标中增加了一个正则化项（$ \\lambda \\sum w^2 $），其中 $ \\lambda $ 是正则化参数。\n",
    "- **目标**：不仅最小化预测值和实际值之间的差异，还要最小化权重的平方和。\n",
    "\n",
    "#### 岭回归适用场景\n",
    "\n",
    "- 当数据特征间存在多重共线性时（即特征间高度相关）。\n",
    "- 在避免过拟合特别重要的场景。\n",
    "\n",
    "### 线性回归与岭回归的比较\n",
    "\n",
    "| 特点 | 线性回归 | 岭回归 |\n",
    "|------|----------|--------|\n",
    "| 模型复杂度 | 简单，易于理解 | 略复杂，引入正则化 |\n",
    "| 防止过拟合 | 无特定机制 | 强大的防过拟合能力（正则化） |\n",
    "| 处理共线性 | 容易受影响 | 更好地处理共线性问题 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: -23.747 (11.143)\n"
     ]
    }
   ],
   "source": [
    "# 线性回归\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM',\n",
    "            'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = read_csv(filename, delim_whitespace = True, names = names)\n",
    "array = data.values\n",
    "X = array[:, 0:13]\n",
    "Y = array[:, 13]\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "model = LinearRegression()\n",
    "result = cross_val_score(model, X, Y, cv = kfold, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "print('LinearRegression: %.3f (%.3f)' % (result.mean(), result.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
