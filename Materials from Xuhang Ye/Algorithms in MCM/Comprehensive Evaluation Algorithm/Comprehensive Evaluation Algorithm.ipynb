{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 综合评价算法\n",
    "\n",
    "## 引言：综合评价模型的基本概念\n",
    "\n",
    "### 评价模型简介\n",
    "\n",
    "评价模型是一种工具，用于**量化和评估不同的对象或情况**，它通常用于**决策支持、绩效评估、资源分配**等场景，这种模型的主要目的是将**主观或定性的评价**转化为**客观或定量的评分**。\n",
    "\n",
    "### 综合评价模型的组成要素\n",
    "\n",
    "1. **被评价对象与主体**：评价对象是评价的**焦点**，如一个项目、产品或服务。评价主体则是**进行评价的个人或团队**。\n",
    "   \n",
    "2. **评价标准与因素**：这些是用来评价对象的准则，涉及到评价对象的重要性和质量。因素可能是**宏观**的，如可行性、效益等。\n",
    "   \n",
    "3. **评价指标**：这些是**具体的、可量化的**标准，用于对评价对象进行**细致的评估**。它们应该遵循“四性原则”：可度量性、典型性、独立性和内涵性。\n",
    "   \n",
    "4. **评价方法**：这是评价指标的**具体应用方式**，将抽象的概念转化为量化的指标。\n",
    "   \n",
    "5. **综合评价模型**：这个模型整合了以上所有要素，形成一个完整的评价系统。\n",
    "\n",
    "### 综合评价算法实施步骤\n",
    "\n",
    "1. **建立模型**：根据具体问题定义评价模型的目标和对象。\n",
    "\n",
    "2. **预处理**：\n",
    "   - **归一化**：统一不同指标的量度标准，使其可比。\n",
    "   - **相关性检查**：确定指标之间的相关性，以避免重复或相互影响。\n",
    "\n",
    "3. **明确评价标准**：确定评价的主要准则和它们的重要性。\n",
    "\n",
    "4. **评价因素与指标细化**：按照可度量性（重要性）、典型性（不是越多越好）、独立性（可区分且独立）和内涵性（清晰的现实意义）原则，将评价因素细化为具体的评价指标。\n",
    "\n",
    "5. **构建评价体系**：将评价因素和指标组织成一个结构化的体系。\n",
    "\n",
    "6. **处理指标**：将评价指标转化为可量化的数值，如通过排序或计算逆序数等方法。\n",
    "\n",
    "### 评价模型的应用场景\n",
    "\n",
    "评价模型适用于**需要量化比较和评估**的情况，尤其是当**评价标准不完全客观或有多个标准**需要考虑时。\n",
    "\n",
    "#### 1. 货比三家\n",
    "- **场景**：比较不同产品或服务的优劣。\n",
    "- **适用性**：当需要对一个或多个维度（如价格、质量、功能）进行横向比较时，评价模型可以帮助量化这些标准，并提供一个结果或方案。\n",
    "\n",
    "#### 2. KPI（关键绩效指标）\n",
    "- **场景**：评估员工、部门或公司的绩效。\n",
    "- **适用性**：适用于将多个绩效指标综合考虑，特别是当这些指标各自重要性不同时，评价模型能帮助分配不同的权重。\n",
    "\n",
    "#### 3. 瘦死骆驼比马大\n",
    "- **场景**：比较两个在不同方面表现不一的对象。\n",
    "- **适用性**：当比较对象在某些方面优于另一个，而在其他方面则不如时，评价模型可以提供一个公平的比较方法，通过量化各个方面的重要性。\n",
    "\n",
    "#### 4. 考试类（考研、高考分值划分）\n",
    "- **场景**：学术或技能评估。\n",
    "- **适用性**：评价模型适用于将不同科目或评估标准合成一个总分，尤其在每个标准的重要性不同时。\n",
    "\n",
    "#### 5. 主观倾向性评价\n",
    "- **场景**：涉及专家意见、个人偏好的评估（如面试评分）。\n",
    "- **适用性**：评价模型可以帮助规范化这些主观判断，通过预先定义的标准和权重来减少个人偏见。\n",
    "\n",
    "### 评价指标的具体应用方法\n",
    "\n",
    "1. 熵权-秩和比法（AHP模型、熵权法、秩和比法）\n",
    "   \n",
    "2. 随机熵权-TOPSIS 法\n",
    "   \n",
    "3. CRITIC-秩和比法\n",
    "   \n",
    "4. G2定权法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 熵权-秩和比法（AHP模型、熵权法、秩和比法）\n",
    "\n",
    "### AHP模型（Analytic Hierarchy Process）(主观因素较大)\n",
    "\n",
    "层次分析法（AHP，Analytic Hierarchy Process）是一个非常强大的决策支持工具，广泛应用于各种复杂决策问题中。AHP由美国运筹学家托马斯·L·萨蒂（Thomas L. Saaty）在20世纪70年代提出，其主要特点是通过将复杂的决策问题分解为易于理解和分析的层次结构。\n",
    "\n",
    "#### AHP模型的基本步骤\n",
    "\n",
    "1. **建立层次结构**：\n",
    "   - **目标层**：决策的主要目的或需要解决的问题。\n",
    "   - **准则层**：影响决策的因素或标准。\n",
    "   - **方案层**：可供选择的备选方案。\n",
    "\n",
    "   例如，如果一个公司要选择新的办公地点，目标层是选择最佳的办公地点，准则层可能包括成本、位置、交通便利性等，方案层则是具体的地点选项。\n",
    "\n",
    "2. **构造判断矩阵**：\n",
    "   - 在每一个准则层，通过成对比较各准则的重要性，构造出一个判断矩阵。\n",
    "   - 利用1到9的标度进行评分，其中1表示两个元素同等重要，9表示一个元素比另一个元素重要得多。\n",
    "   - 这个过程主要依赖专家的主观判断。\n",
    "\n",
    "3. **一致性检验**：\n",
    "   - 为了确保判断的合理性，需要对判断矩阵进行一致性检验。\n",
    "   - 通过计算一致性比例（CR，Consistency Ratio）来评估这个矩阵的一致性。一般来说，CR值小于0.1时，判断矩阵的一致性是可以接受的。\n",
    "\n",
    "4. **合成权重的计算**：\n",
    "   - 从判断矩阵中计算出各准则或方案的相对权重。\n",
    "   - 这些权重反映了各准则或方案相对于总目标的重要性。\n",
    "\n",
    "5. **选择最佳方案**：\n",
    "   - 结合各层的权重，计算出各个方案的综合评分。\n",
    "   - 最高分的方案被认为是最佳选择。\n",
    "\n",
    "#### AHP模型的应用\n",
    "AHP模型特别适用于那些涉及多个准则或标准的决策问题。它的优势在于能够结合定性和定量的分析，使决策过程更加透明和系统化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据的归一化\n",
    "\n",
    "实际上，在构建AHP模型时，首先要对数据进行归一化，下面是三种常用的归一化方法：\n",
    "\n",
    "1. Min-max normalization (Rescaling)\n",
    "2. Mean normalization （与方法1相似，只不过使数据以0为均值）\n",
    "3. Z-score normalization (Standardization)\n",
    "4. L2 normalization\n",
    "\n",
    "对于其中三种较重要的方法的对比\n",
    "\n",
    "| 归一化方法 | 适用场景 | 说明 |\n",
    "|------------|----------|------|\n",
    "| Min-max normalization (Rescaling) |  当数据需要被限制在特定范围内（如0到1）<br> 神经网络等需要固定范围输入的算法<br> 数据特征的原始范围差异较大 | 适用于需要将数据规范到固定区间，特别是在需要保留原始数据中的最小和最大值信息时 |\n",
    "| Z-score normalization (Standardization) |  数据假定接近正态分布<br> 线性回归、逻辑回归、判别分析等统计方法<br> 当数据分布不明显偏斜（没有极端值） | 当算法假设数据是正态分布，或者需要消除量纲影响、标准化数据特征的时候适用 |\n",
    "| L2 normalization (Normalization) |  需要保持数据点间的相对距离<br> K近邻算法、聚类算法<br> 特征尺度差异对分析结果影响显著的情况（如文本数据） | 在非参数模型中，特别是需要保持数据点方向的情况下适用，适合特征间相对比例重要的场景 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  ... 0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 ... 0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 ... 0.347 0.254 0.183]\n",
      " ...\n",
      " [0.294 0.608 0.59  ... 0.39  0.071 0.15 ]\n",
      " [0.059 0.633 0.492 ... 0.449 0.116 0.433]\n",
      " [0.059 0.467 0.574 ... 0.453 0.101 0.033]]\n"
     ]
    }
   ],
   "source": [
    "# Min-max normalization (Rescaling) (按比例缩放，一般不推荐)\n",
    "# K近邻算法\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "from pandas import read_csv\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values\n",
    "X = array[ : , 0 : 8]\n",
    "Y = array[ : , 8]\n",
    "transformer = MinMaxScaler(feature_range = (0, 1)) # feature_range: 指定缩放范围\n",
    "newX = transformer.fit_transform(X) # fit_transform: 拟合数据，然后转化它将其转化为标准形式\n",
    "set_printoptions(precision = 3)\n",
    "\n",
    "print(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15  ...  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161 ... -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 ... -1.103  0.604 -0.106]\n",
      " ...\n",
      " [ 0.343  0.003  0.15  ... -0.735 -0.685 -0.276]\n",
      " [-0.845  0.16  -0.471 ... -0.24  -0.371  1.171]\n",
      " [-0.845 -0.873  0.046 ... -0.202 -0.474 -0.871]]\n"
     ]
    }
   ],
   "source": [
    "# Z-score normalization (Standardization)（数据假定接近正态分布，使数据具有0均值和单位方差）\n",
    "# 线性回归、逻辑回归、判别分析\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler().fit(X)\n",
    "newX = transformer.transform(X)\n",
    "\n",
    "print(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 ... 0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 ... 0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 ... 0.118 0.003 0.162]\n",
      " ...\n",
      " [0.027 0.651 0.388 ... 0.141 0.001 0.161]\n",
      " [0.007 0.838 0.399 ... 0.2   0.002 0.313]\n",
      " [0.008 0.736 0.554 ... 0.241 0.002 0.182]]\n"
     ]
    }
   ],
   "source": [
    "# L2 normalization (Normalization)（调整数据集中每个样本的特征向量，使其具有单位范数（长度为1），这会使得每个样本的各个特征值的平方和为1）（更推荐）\n",
    "# 神经网络、文本分类、聚类算法、K近邻算法\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "transformer = Normalizer().fit(X)\n",
    "newX = transformer.transform(X)\n",
    "\n",
    "print(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判断矩阵\n",
    "\n",
    "![Judgement Matrix](Judgement_Matrix.jpg)\n",
    "\n",
    "- 算数平均法求权重\n",
    "  1. 将判断矩阵按照归一化（每个元素除以所在列的和）\n",
    "  2. 将归一化的各列相加（即为按行求和）\n",
    "  3. 将相加后得到向量每个元素除以特征值，可以得到权重向量\n",
    "\n",
    "- 一致性检验\n",
    "  1. 为了防止出现矛盾，则判断矩阵满足 $ a_{i,k} \\cdot a_{k,j} = a_{i,j} $，这样的矩阵为一致矩阵。（穷举法）\n",
    "  2. 计算一致性指标CI，查找对应的平均随机一致性指标RI，最终得到一致性比例系数$ CR = \\frac{CI}{RI} $，如果CR<0.1，则判断矩阵满足一致性\n",
    "\n",
    "$$ CI = \\frac{\\lambda_{max} - n}{n - 1} $$\n",
    "\n",
    "![RI](RI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵权法（客观定权）\n",
    "\n",
    "#### 熵权法相关基本概念\n",
    "\n",
    "1. **信息论的基础**：由香农提出的，它用数学的方法来量化信息。在信息论中，**信息熵**是一个核心概念，它描述了一个系统的不确定性。在这里，我们用它来描述一个指标的不确定性，也就是它的变化程度。信息熵越高，表示该指标的数据越分散，反之则数据越集中。\n",
    "\n",
    "2. **信息熵（Information Entropy）**：这个概念最初由克劳德·香农在信息论中引入，用以衡量**信息的不确定性或无序程度**。比如如果预报员说“明天下雨的概率是50%”，这包含了很多不确定性。但如果他们说“明天一定下雨”，这就很确定，不确定性很小。**信息熵正是用来量化这种不确定性的。**\n",
    "\n",
    "3. **熵权法（Entropy Weight Method）**：这是一种基于信息熵原理的数据分析方法。在评价多个指标时，我们需要决定每个指标的重要性或权重。熵权法通过计算每个指标的信息熵来决定其权重，如果一个指标的**数据变化很大（即离散程度高）**，它的信息熵就会**较低**，意味着这个指标提供了更多的信息，因此应该赋予**更大的权重**。\n",
    "\n",
    "简单来说，就像你在一个有很多声音的房间里，那些声音变化最大、最不可预测的（即“最吵闹的”），往往最能吸引你的注意。在熵权法中，这些“最吵闹的”指标，因为它们的信息量大，所以在整体评价中占据更重要的地位。\n",
    "\n",
    "\n",
    "#### 熵权法的计算步骤\n",
    "\n",
    "1. 标准化\n",
    "   - **目的**：将所有指标转换为非负数值，以便它们可以被解释为概率。\n",
    "   - **方法**：使用最小-最大标准化（Min-max normalization），对于矩阵中的每个元素 $ x $，标准化公式为：\n",
    "   $$ x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} $$\n",
    "   - **结果**：得到一个新的矩阵，所有元素都在 [0,1] 区间。\n",
    "\n",
    "2. 计算比重（概率）\n",
    "   - **目的**：确定每个样本在每个指标下的相对重要性。\n",
    "   - **公式**：对于第 $ i $ 个样本的第 $ j $ 个指标 $ x_{ij} $，其比重 $ p_{ij} $ 计算为：\n",
    "   $$ p_{ij} = \\frac{x'_{ij}}{\\sum_{i=1}^{n} x'_{ij}} $$\n",
    "   - **说明**：这里 $ x'_{ij} $ 是标准化后的值，分母是第 $ j $ 个指标下所有样本标准化值的总和。\n",
    "\n",
    "3. 计算信息熵\n",
    "   - **目的**：评估每个指标的不确定性。\n",
    "   - **公式**：第 $ j $ 个指标的信息熵 $ e_j $ 由下式给出：\n",
    "   $$ e_j = -\\frac{1}{\\ln(n)} \\sum_{i=1}^{n} p_{ij} \\ln(p_{ij}) $$\n",
    "   - **说明**：这里 $ n $ 是样本的数量，分母 $ \\ln(n) $ 是为了正规化信息熵值。\n",
    "\n",
    "4. 计算差异值\n",
    "   - **公式**：第 $ j $ 个指标的差异值 $ d_j $ 计算为：\n",
    "   $$ d_j = 1 - e_j $$\n",
    "\n",
    "5. 计算权重\n",
    "   - **目的**：确定每个指标在综合评价中的相对重要性。\n",
    "   - **公式**：第 $ j $ 个指标的权重 $ \\omega_j $ 计算为：\n",
    "   $$ \\omega_j = \\frac{d_j}{\\sum_{j=1}^{m} d_j} $$\n",
    "   - **说明**：权重是各个指标的差异值归一化的结果，确保所有权重之和为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 秩和比法\n",
    "\n",
    "#### 秩和比法的基本原理\n",
    "\n",
    "秩和比法（Rank Sum Ratio, RSR）是一种用于评价和比较多个对象或实验条件下的综合效果的非参数统计方法。这种方法不依赖于数据的**具体分布**，而是通过数据的**相对排名**来进行分析。\n",
    "\n",
    "在这个方法中，我们通常有一个 $ n $ 行 $ m $ 列的数据矩阵，其中 $ n $ 是样本的数量，$ m $ 是评价指标的数量。这个矩阵可以看作是一个比赛的成绩单，每一行代表一个参赛者（或评价对象），每一列代表一个比赛项目的成绩。\n",
    "\n",
    "基本原理可以这样理解：\n",
    "\n",
    "1. **秩转换**：我们首先对每个指标（列）的数据进行排序，并赋予每个数据一个秩次。例如，在赛跑比赛中，第一个跑过终点线的人获得第一名，也就是秩为1，以此类推。\n",
    "\n",
    "2. **无量纲化**：通过转换为秩，我们把原始数据转化为了无量纲的统计量，使得不同尺度或单位的数据可以公平比较。\n",
    "\n",
    "3. **RSR计算**：对于每个样本，我们将其所有指标的秩次相加得到一个总秩和，然后用这个总秩和除以一个标准化值（通常是该样本在所有指标上都获得最高秩时的秩和），得到秩和比。\n",
    "\n",
    "4. **综合评价**：通过RSR值，我们可以对样本进行排序，RSR值越大，表示样本在所有指标上的综合表现越好。\n",
    "\n",
    "#### 样本秩的概念：\n",
    "\n",
    "样本秩是指在一个样本集中，每个数值按照其大小顺序被赋予的排名。如果你有一组数值 $ x_1, x_2, \\ldots, x_n $，它们可以按照从小到大(或从大到小)排序。每个数值在排序后的位置就是它的秩。秩次为样本提供了一种在群体中的相对位置度量。\n",
    "\n",
    "例如，假设我们有一组数据 $ [3, 1, 4] $。当我们将它们排序 $ [1, 3, 4] $ 后，数值1的秩是1，数值3的秩是2，数值4的秩是3。\n",
    "\n",
    "样本秩处理的一个特殊情况是**并列秩**。如果数据中有相同的数值（即平局），我们会赋予它们的秩是它们在没有平局情况下应有秩次的平均值。\n",
    "\n",
    "#### 秩和比法基本步骤\n",
    "\n",
    "1. 选择评价指标并确定指标类型\n",
    "\n",
    "    在应用秩和比法之前，首先需要确定评价对象和评价指标。\n",
    "\n",
    "   - **效益型指标**：这类指标是“越大越好”的。\n",
    "   - **成本型指标**：这类指标是“越小越好”的。\n",
    "   - **中性型指标**：这类指标并不明确指出数值大或小更好，可能根据具体情况而定。\n",
    "\n",
    "    评价的第一步是构建一个数据矩阵，其中包括 $ n $ 个评价对象和 $ m $ 个评价指标。\n",
    "\n",
    "2. 秩和比法的两种概念\n",
    "\n",
    "   - **整次秩和比法**：这种方法要求按指标类型将每个指标下的评价对象值进行排序，并赋予秩次。对于效益型指标，值从小到大排列；对于成本型指标，值从大到小排列。如果存在相同的数值，即并列情况，赋予相同数值的平均秩。\n",
    "\n",
    "   - **非整次秩和比法**：这种方法旨在保持原始指标值的定量信息，编排的秩次与原始指标值之间存在定量的线性关系，从而避免在秩次化过程中损失信息。\n",
    "\n",
    "3. RSR计算方法\n",
    "\n",
    "   - **计算RSR（权重相同）**：\n",
    "    对于每个评价对象，计算其所有指标的秩次之和，并除以 $ n \\times m $，即评价对象数乘以指标数。\n",
    "        $$ RSR_i = \\frac{1}{n \\times m} \\sum_{j=1}^{m} R_{ij} $$\n",
    "        其中 $ R_{ij} $ 是第 $ i $ 个评价对象在第 $ j $ 个指标的秩次。\n",
    "\n",
    "   - **计算WRSR（权重不同）(更推荐）**：\n",
    "    对于每个评价对象，按照各指标的重要性赋予不同的权重 $ W_j $，计算加权秩和比。（ $ W_j $ 这个数据就是通过AHP或熵权法得到的）\n",
    "        $$ WRSR_i = \\frac{1}{n} \\sum_{j=1}^{m} W_j R_{ij} $$\n",
    "        其中 $ W_j $ 是第 $ j $ 个指标的权重。\n",
    "\n",
    "4. RSR分布的确认\n",
    "\n",
    "   - 通过计算所有评价对象的RSR或WRSR值，我们可以编制一个RSR（或WRSR）频率分布表。\n",
    "   - 列出各组频数 $ f $，计算各组累积频数 $ cf $，然后计算累积频率 $ p_i = \\frac{cf_i}{n} $。\n",
    "   - 将累积频率 $ p_i $ 转换为概率单位 $ probit_i $，即标准正态分布的 $ p_i $ 分位数加5。\n",
    "\n",
    "5. 计算直线回归方程\n",
    "\n",
    "   - 以累积频率对应的概率单位 $ probit_i $ 为自变量，以RSR（或WRSR）值为因变量，计算直线回归方程：\n",
    "  $$ RSR \\text{ (或 } WRSR \\text{) } = a + b \\times \\text{Probit} $$\n",
    "\n",
    "6. 分档排序\n",
    "\n",
    "   - 使用回归方程将评价对象进行分档排序，这可以基于它们的RSR或WRSR值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
