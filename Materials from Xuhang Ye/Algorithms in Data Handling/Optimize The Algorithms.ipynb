{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.773462 (0.048998)\n",
      "LDA: 0.766969 (0.047966)\n",
      "KNN: 0.710988 (0.050792)\n",
      "CART: 0.690260 (0.058210)\n",
      "NB: 0.759142 (0.038960)\n",
      "SVM: 0.760458 (0.034712)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 算法比较\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import BaseShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(multi_class = 'multinomial', max_iter = 3000)\n",
    "models['LDA'] = LinearDiscriminantAnalysis()\n",
    "models['KNN'] = KNeighborsClassifier()\n",
    "models['CART'] = DecisionTreeClassifier()\n",
    "models['NB'] = GaussianNB()\n",
    "models['SVM'] = SVC()\n",
    "\n",
    "results = []\n",
    "for key in models:\n",
    "    result = cross_val_score(models[key], X, Y, cv = kfold)\n",
    "    results.append(result)\n",
    "    print('%s: %f (%f)' % (key, result.mean(), result.std()))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111) # 1行1列第1个\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(models.keys()) # 设置x轴标签\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法的优化\n",
    "\n",
    "## 集成算法\n",
    "\n",
    "### 集成算法的基本概念\n",
    "\n",
    "集成算法是一种机器学习技术，其核心思想是**将多个学习模型组合起来，以提高整体模型的性能**，尤其是在**准确性**方面。这种方法基于一个简单但强大的前提：多个模型结合的预测结果通常比任何单一模型的预测结果更为准确和可靠。集成算法特别适用于解决单一模型难以克服的复杂问题，如过拟合或者对特定数据集的泛化能力较差的问题。\n",
    "\n",
    "### 集成算法的关键要素：\n",
    "1. **模型的多样性**：集成算法依赖于多个模型的多样性，每个模型学习数据的方式都略有不同。这些模型可以是同一算法的不同版本，或者是完全不同的算法。\n",
    "\n",
    "2. **错误校正**：通过将多个模型的预测结果结合起来，可以减少单个模型可能产生的偏差和误差。这种集成方法能够在多个模型之间平衡误差，从而提高整体的预测准确性。\n",
    "\n",
    "3. **减少过拟合**：单个模型可能会过度学习训练数据中的细节和噪声，导致其泛化能力下降（即在新数据上的表现不佳）。集成算法通过结合多个模型的预测，可以减轻这种过拟合的风险。\n",
    "\n",
    "### 集成算法的主要类型：\n",
    "1. **装袋（Bagging）**：它通过对原始训练数据进行多次随机采样（可重复抽样），创建多个**不同的训练数据子集**，然后**对每个数据子集训练一个模型**。最后，这些模型的预测结果被平均（回归问题）或投票（分类问题）来获得最终结果。典型的例子是随机森林算法。（并联）\n",
    "\n",
    "2. **提升（Boosting）**：这种方法涉及到**按顺序**训练模型，**每一个后续的模型都致力于纠正前一个模型的错误**。提升算法的目标是增强模型的性能。在这个过程中，模型变得越来越专注于训练数据中**难以预测的部分**。著名的例子包括AdaBoost和梯度提升机（GBM）。（串联）\n",
    "\n",
    "3. **堆叠（Stacking）**：在这种方法中，不同的模型被训练以解决同一个问题，然后一个新的模型（通常称为元模型）被训练来汇总这些模型的预测结果。堆叠方法尝试学习各个模型的预测结果如何结合起来可以提供最佳的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 袋装算法（Bagging）\n",
    "\n",
    "- 装袋算法是一种提高**分类准确率**的算法，通过给定组合**投票**的方式获得最优解。\n",
    "- 比如你生病了，去n个医院看了n个医生，每个医生都给你开了药方，最后哪个药方的出现次数多，就说明这个药方越有可能是最优解，这很好理解，这也是装袋算法的思想。\n",
    "\n",
    "- 一共有三种装袋模型，将依次介绍：\n",
    "  1. 装袋决策树(Bagged Decision Trees)\n",
    "  2. 随机森林(Random Forest)\n",
    "  3. 极端随机树(Extra Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 装袋决策树（Bagged Decision Trees）\n",
    "\n",
    "- **概念**：装袋算法，特别是在决策树中的应用，是通过创建**多个决策树模型**的集合来提高分类的准确率。每个决策树都在数据集的**不同随机子集**上训练，最终通过投票的方式来确定最终的预测结果。\n",
    "  \n",
    "- **过程**：在装袋算法中，每个决策树都是**独立建立**的。算法从原始数据集中**随机选择（有放回抽样）子集**来训练每个树模型。这意味着，相同的样本可能在多个不同的树中被重复使用。最后，所有决策树的输出汇聚起来（例如，通过投票）以产生最终结果。\n",
    "\n",
    "- **优势**：这种方法减少了模型对特定数据样本的敏感性，从而降低过拟合的风险。装袋决策树特别适用于**高方差**的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578263841421736\n"
     ]
    }
   ],
   "source": [
    "# 装袋决策树\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(estimator = cart, n_estimators = num_trees, random_state = 7)\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 随机森林（Random Forest）(Most Recommended)\n",
    "\n",
    "- **概念**：随机森林是装袋算法的一个扩展，由许多决策树组成。每棵树的训练都是独立的，并且在进行预测时，随机森林考虑所有树的输出来做出最终决策。\n",
    "\n",
    "- **特点**：在构建每棵树时，随机森林不仅**随机选择样本（行采样）（有放回）**，而且还**随机选择特征（列采样）**。这增加了模型的多样性，并进一步减少了过拟合的风险。\n",
    "\n",
    "- **不剪枝**：与传统决策树相比，随机森林通常不对树进行剪枝。由于集成了许多树的预测，即使单棵树可能对某些样本的预测有偏差，整体模型仍然能够保持稳定的预测准确率。\n",
    "\n",
    "- **类比理解**：每一棵决策树就是一个精通某一个领域的专家，这样在随机森林中就有了很多个精通不同领域的专家，对于一个新的问题（新的输入数据），可以从不同的角度去看待它，最\n",
    "终由各个专家投票得到结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759107997265892\n"
     ]
    }
   ],
   "source": [
    "# 随机森林\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "model = RandomForestClassifier(n_estimators = 100, random_state = 7, max_features = 3)\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 极端随机树（Extra Trees）(Less Recommended)\n",
    "\n",
    "- **概念**：极端随机树算法与随机森林类似，但在分裂节点时采取更加随机的策略。\n",
    "\n",
    "- **区别**：\n",
    "  1. **样本使用**：与随机森林使用有放回抽样不同，极端随机树通常使用全部的训练数据来训练每一棵树。\n",
    "  2. **特征分裂**：在确定分裂节点时，随机森林会在随机选择的特征子集中找到最优分裂，而极端随机树则是完全随机选择分裂点，这增加了模型的随机性。\n",
    "\n",
    "- **优势与应用**：极端随机树因其随机性在某些情况下可以提供比随机森林更好的性能，特别是在需要降低模型训练时间的情况下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7630211893369789\n"
     ]
    }
   ],
   "source": [
    "# 极端随机树\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "model = ExtraTreesClassifier(n_estimators = 100, random_state = 7, max_features = 3)\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提升算法（Boosting）\n",
    "\n",
    "提升算法是一种强大的集成技术，用于提高一系列弱分类器的整体性能。这种方法的核心在于将多个简单的模型（通常称为弱学习器）组合成一个强大的整体模型。提升算法与装袋算法的主要区别在于，它是**按顺序**逐步构建模型（串联），而不是**并行构建**（并联）。\n",
    "\n",
    "- 提升算法的工作原理：\n",
    "  1. **序列模型构建**：在提升算法中，每个新的模型都是**在之前模型的基础上**构建的。初始时，算法从一个简单的模型开始，然后逐步添加新模型，**每个新模型都致力于改正前一个模型的错误**。\n",
    "  2. **强调错误**：提升算法通过增加那些被之前模型错误分类的样本的权重，来引导后续模型的学习。这意味着随着每一轮的学习，算法都会更加关注那些难以分类的案例。\n",
    "  3. **加权投票**：最终的模型是通过组合所有简单模型的加权预测结果得出的。在这个过程中，每个模型的影响力通常取决于其准确性，准确性更高的模型会有更大的权重。\n",
    "\n",
    "- 提升算法的关键优点：\n",
    "  1. **减少偏差**：提升算法主要是减少模型的偏差，即它能够帮助模型在训练数据上取得更好的表现。\n",
    "  2. **提高准确度**：即使基学习器的性能较弱，通过逐步提升也能达到很高的准确度。\n",
    "  3. **降低过拟合的风险**：虽然提升算法在每一步都增加模型复杂度，但它**通常不会导致过拟合**。\n",
    "\n",
    "- 常见的提升算法：\n",
    "  1. **AdaBoost（自适应增强）**：AdaBoost是最初的提升算法之一，它通过在每一轮中调整样本的权重，使得之前分类错误的样本在后续模型中得到更多关注。\n",
    "  2. **随机梯度提升（Stochastic Gradient Boosting）**：这种方法结合了梯度提升的思想和随机性。在每一步，它不仅关注于减少模型的损失函数，而且还通过随机选择样本和特征来增加训练过程的随机性，从而提高模型的鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. AdaBoost\n",
    "\n",
    "AdaBoost（Adaptive Boosting）是提升算法家族中最著名和广泛使用的算法之一。它的核心思想是将多个弱分类器（通常是非常简单的模型）组合成一个强分类器。(迭代思想与加权思想)\n",
    "\n",
    "##### AdaBoost工作原理：\n",
    "1. **初始化权重**：AdaBoost以等权重开始训练数据中的每个样本。\n",
    "2. **迭代训练**：在每一轮迭代中，算法训练一个弱分类器。最初，所有的样本都被平等对待。\n",
    "3. **更新权重**：在每轮迭代后，**被错误分类的样本的权重会增加，而正确分类的样本的权重会减少**。这意味着随着算法的进行，模型会越来越关注那些难以正确分类的样本。\n",
    "4. **模型加权**：每个弱分类器都会根据其准确性被赋予一个权重,**更准确的分类器会有更高的权重**。\n",
    "5. **组合模型**：最终的模型是这些加权弱分类器的组合。\n",
    "\n",
    "##### AdaBoost特点：\n",
    "- **适用性**：AdaBoost对分类问题特别有效，它能够排除不必要的训练数据特征，关注最有影响的特征。\n",
    "- **灵活性**：可以与任何学习算法结合，不限于决策树。\n",
    "- **自适应性**：在每一轮中自动调整，能够自适应地改进分类器的性能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552802460697198\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "model = AdaBoostClassifier(n_estimators = 30, random_state = 7)\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 随机梯度提升（Gradient Boosting）\n",
    "\n",
    "随机梯度提升（Stochastic Gradient Boosting）是一种更先进的提升技术，它基于梯度提升机（GBM）的思想，但引入了随机性来提高鲁棒性。\n",
    "\n",
    "#### 随机梯度提升工作原理：\n",
    "1. **梯度提升**：基本概念是逐步构建模型，每一步都尝试纠正前一步的错误。它通过最小化损失函数的梯度来优化模型。\n",
    "2. **随机性引入**：与传统GBM相比，随机梯度提升在每一步中不是使用所有数据，而是使用数据的随机子集来训练基学习器，这减少了方差，增加了模型的泛化能力。\n",
    "3. **逐步优化**：每个新模型都是为了减少整体模型的损失。该算法会计算损失函数的梯度，并使用这个信息来更新模型。\n",
    "\n",
    "#### 随机梯度提升特点：\n",
    "- **效率高**：由于每次只用部分样本，计算效率高于传统GBM。\n",
    "- **避免过拟合**：随机选择子集有助于降低过拟合风险。\n",
    "- **灵活应用**：适用于各种类型的预测问题，包括分类和回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591934381408066\n"
     ]
    }
   ],
   "source": [
    "# 随机梯度提升\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "model = GradientBoostingClassifier(n_estimators = 100, random_state = 7)\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 投票算法（Voting）\n",
    "\n",
    "投票算法（Voting）是一种在集成学习中常见的技术，它结合了多个不同的模型来做出最终的预测。这种方法基于一个简单的前提：多个模型共同作出的决策通常比任何单个模型作出的决策更为准确和可靠。\n",
    "\n",
    "- 投票算法的工作原理：\n",
    "  1. **组合模型**：在投票算法中，首先会创建**两个或多个不同的机器学习模型**。这些模型可以是完全不同的算法（如决策树、支持向量机、K近邻等）。\n",
    "  2. **预测与投票**：每个模型都会对相同的数据集进行预测。在分类问题中，'投票'通常是指**选择多数模型预测为某一类别的那个类别**。这可以是简单多数投票（硬投票）或平均概率投票（软投票）。\n",
    "  3. **硬投票与软投票**：\n",
    "      - **硬投票**：每个模型的预测结果被视为一个'投票'，最终结果是基于**最多投票**的类别。\n",
    "      - **软投票**：考虑每个模型预测每个类别的概率，最终结果是基于**平均概率最高**的类别。\n",
    "  4. **加权投票**：尽管scikit-learn中的`VotingClassifier`默认不提供加权投票机制，我们仍可以通过调整模型在集成中的权重来间接实现加权投票。这种方法可以使某些模型对最终预测的影响更大。\n",
    "\n",
    "- 投票算法的应用场景：\n",
    "  1. **提高准确度**：当有多个表现良好但差异较大的模型时，使用投票算法可以提高预测的准确性。\n",
    "  2. **减少过拟合**：由于模型的多样性，投票算法可以减少过拟合的风险，提高模型在未见数据上的泛化能力。\n",
    "  3. **实现简单**：投票算法相比其他更复杂的集成方法（如堆叠）来说，实现起来更为简单直接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708646616541354\n"
     ]
    }
   ],
   "source": [
    "# 投票算法\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier # 装袋决策树\n",
    "from sklearn.svm import SVC # 支持向量机\n",
    "from sklearn.linear_model import LogisticRegression # 逻辑回归\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
    "# 基模型\n",
    "estimators = []\n",
    "model_lr = LogisticRegression(multi_class = 'multinomial', max_iter = 3000)\n",
    "estimators.append(('logistic', model_lr))\n",
    "model_cart = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model_cart))\n",
    "model_svc = SVC()\n",
    "estimators.append(('svm', model_svc))\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = cross_val_score(ensemble, X, Y, cv = kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法调参\n",
    "\n",
    "在机器学习中，算法调参（或超参数优化）是一个关键的步骤，它直接影响着模型的性能和预测准确度。超参数是指在学习过程开始之前设置的参数，与模型训练过程中学习的参数不同。正确的调参可以显著提高模型对新数据的预测能力。\n",
    "\n",
    "### 调参的重要性\n",
    "\n",
    "1. **影响模型性能**：不同的参数设置会导致截然不同的模型性能。\n",
    "2. **过拟合与欠拟合**：调整参数可以帮助模型在训练集上取得更好的准确度，同时防止过拟合，即保持对新数据的泛化能力。\n",
    "\n",
    "### 参数类型\n",
    "\n",
    "1. **影响训练准确度或防止过拟合的参数**：例如，决策树的深度、神经网络的层数或学习速率等。（主要）\n",
    "2. **不影响准确度或过拟合的参数**：通常关于计算效率，如随机森林中的树的数量等。\n",
    "\n",
    "### 调参原则\n",
    "\n",
    "遵循**偏差**与**方差**协调的原则。\n",
    "\n",
    "### 自动寻找最优化参数的方法\n",
    "\n",
    "1. 网格搜索（Grid Search）\n",
    "2. 随机搜索（Random Search）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索（Grid Search）\n",
    "\n",
    "#### 网格搜索的概念\n",
    "网格搜索是一种超参数优化技术，用于系统地遍历多种预设的参数组合，以找到最佳的模型配置。这种方法通过指定一个参数值的'网格'，然后尝试网格中的每一种组合，来确定哪一组参数为模型提供了最佳性能。\n",
    "\n",
    "#### 网格搜索的过程\n",
    "\n",
    "1. **定义参数网格**：确定想要优化的**模型参数**及**其可能的值范围**。\n",
    "2. **选择评分标准**：确定用于评估模型性能的标准，如**准确率**或**均方误差**。\n",
    "3. **设置交叉验证**：确定**交叉验证的方法**，以便在不同的数据子集上评估模型。\n",
    "4. **遍历参数组合**：系统地测试参数网格中的所有参数组合。\n",
    "5. **选择最优组合**：根据评分标准选择表现最好的参数组合。\n",
    "6. **重新训练模型**：使用最优参数组合在全部数据上重新训练模型。\n",
    "\n",
    "#### 网格搜索的优点\n",
    "1. **系统性**：能够**穷尽**搜索参数网格中的所有可能组合，保证了找到最优参数的可能性。\n",
    "2. **简单直接**：易于理解和实现，尤其适合参数数量较少时使用。\n",
    "3. **全面性**：由于它遍历了所有可能的参数组合，因此对于较小的数据集和较少的参数组合，它非常有效。\n",
    "\n",
    "#### 网格搜索的缺点\n",
    "1. **计算成本高**：随着参数数量和范围的增加，需要评估的模型数量呈指数级增长，可能导致计算成本非常高。\n",
    "2. **效率低**：对于每一种参数组合，网格搜索都需要从头到尾完整地训练模型，即使某些参数的效果明显较差。\n",
    "3. **灵活性差**：固定的网格限制了搜索的灵活性。如果最优参数落在网格之外，网格搜索无法找到它。\n",
    "\n",
    "#### 网格搜索的应用场景\n",
    "网格搜索适合于参数数量较少，且对每个参数的可能值范围有较好理解的情况。在这些情况下，它可以提供一个简单且有效的方法来优化模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score: 0.276\n",
      "The best estimator: 1\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge # 岭回归\n",
    "from sklearn.model_selection import GridSearchCV # 网格搜索\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "model = Ridge()\n",
    "para_grid = {'alpha': [1, 0.1, 0.01, 0.001, 0]}\n",
    "grid = GridSearchCV(estimator = model, param_grid = para_grid)\n",
    "grid.fit(X, Y)\n",
    "\n",
    "print(\"The best score: %.3f\" % grid.best_score_)\n",
    "print(\"The best estimator:\", grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机搜索优化参数（Random Search for Hyperparameter Optimization）\n",
    "\n",
    "随机搜索优化参数（Random Search for Hyperparameter Optimization）是一种高效的参数优化方法，特别适用于**参数空间较大时**的情况。\n",
    "\n",
    "#### 随机搜索优化参数的基本概念\n",
    "\n",
    "随机搜索通过在预定义的参数范围内进行随机采样来寻找最佳参数。与网格搜索不同，它不会尝试所有可能的参数组合，而是从参数的分布中随机选择，进行固定次数的迭代。\n",
    "\n",
    "#### 随机搜索优化参数的过程\n",
    "\n",
    "1. **定义参数分布**：为每个参数定义一个概率分布。例如，可以为正则化参数定义一个均匀分布或对数分布。\n",
    "2. **随机采样**：从这些分布中**随机采样**参数值，而不是像网格搜索那样遍历预设的参数列表。\n",
    "3. **评估模型**：使用这些随机生成的参数组合来训练模型，并通过交叉验证评估其性能。\n",
    "4. **选择最佳参数**：重复此过程固定次数后，选择表现最佳的参数组合。\n",
    "\n",
    "#### 随机搜索优化参数的优点\n",
    "\n",
    "1. **高效性**：特别适用于参数空间庞大的情况，因为它不需要遍历所有可能的参数组合。\n",
    "2. **灵活性**：可以更灵活地定义参数的概率分布。\n",
    "3. **快速收敛**：通常能够更快地找到一个好的和接近最优的参数组合。\n",
    "\n",
    "#### 随机搜索优化参数的缺点\n",
    "\n",
    "1. **可能错过最优解**：由于是随机采样，有可能错过最优参数组合。\n",
    "2. **依赖于迭代次数**：性能很大程度上依赖于迭代的次数，次数太少可能得不到好的结果。\n",
    "\n",
    "#### 随机搜索优化参数的应用场景\n",
    "\n",
    "随机搜索特别适合于**参数维度较高**的情况。在参数数量众多且不清楚哪些参数是影响模型性能的关键因素时，随机搜索提供了一个既高效又实用的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score: 0.276\n",
      "The best estimator: 0.978\n"
     ]
    }
   ],
   "source": [
    "# 随机搜索\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge # 岭回归\n",
    "from sklearn.model_selection import RandomizedSearchCV # 随机搜索\n",
    "from scipy.stats import uniform # 均匀分布\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names = names)\n",
    "\n",
    "array = data.values # 读取数据\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "\n",
    "model = Ridge()\n",
    "para_grid = {'alpha': uniform()} # 默认0-1均匀分布\n",
    "grid = RandomizedSearchCV(estimator = model, param_distributions = para_grid, n_iter = 100, random_state = 7)\n",
    "grid.fit(X, Y)\n",
    "\n",
    "print(\"The best score: %.3f\" % grid.best_score_)\n",
    "print(\"The best estimator: %.3f\" % grid.best_estimator_.alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
